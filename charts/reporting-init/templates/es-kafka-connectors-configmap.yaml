{{ if .Values.es_kafka_connectors.enabled }}
{{ if not .Values.es_kafka_connectors.existingConfigMap }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-es-kafka-connectors-conf
data:
  10.master_doc_type.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="master_doc_type_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_master'; # change this
    DB_TABLES='master.doc_type'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "cr_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "upd_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "del_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec"
          }
    }';
    sleep 20s;
  11.master_registration_center.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="master_registration_center_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_master'; # change this
    DB_TABLES='master.registration_center'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07,tsconvert08,tsconvert09,tsconvert10",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "cr_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "upd_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "del_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "per_kiosk_process_time",
              "transforms.tsconvert06.input.type": "micro_sec",
              "transforms.tsconvert06.output.format": "HH:mm:ss",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "center_start_time",
              "transforms.tsconvert07.input.type": "micro_sec",
              "transforms.tsconvert07.output.format": "HH:mm:ss",

              "transforms.tsconvert08.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert08.field": "center_end_time",
              "transforms.tsconvert08.input.type": "micro_sec",
              "transforms.tsconvert08.output.format": "HH:mm:ss",

              "transforms.tsconvert09.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert09.field": "lunch_start_time",
              "transforms.tsconvert09.input.type": "micro_sec",
              "transforms.tsconvert09.output.format": "HH:mm:ss",

              "transforms.tsconvert10.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert10.field": "lunch_end_time",
              "transforms.tsconvert10.input.type": "micro_sec",
              "transforms.tsconvert10.output.format": "HH:mm:ss"
          }
    }';
    sleep 30s;
  20.audit_app_audit_log.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="audit_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_audit'; # change this
    DB_TABLES='audit.app_audit_log'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "action_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "log_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec"
          }
    }';
  30.prereg_applicant_demographic.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="prereg_applicant_demographic_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_prereg'; # change this
    DB_TABLES='prereg.applicant_demographic,prereg.applicant_demographic_consumed'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "encrypted_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "cr_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "upd_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec"
          }
    }';
  31.prereg_applicant_document.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="prereg_applicant_document_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_prereg'; # change this
    DB_TABLES='prereg.applicant_document,prereg.applicant_document_consumed'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "encrypted_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "cr_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "upd_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.DynamicNewField$Value",
              "transforms.tsconvert06.es.index": '\"$DB_PREFIX_INDEX.master.doc_type\"',
              "transforms.tsconvert06.es.url": '\"$ES_URL\"',
              "transforms.tsconvert06.input.fields": "doc_typ_code,lang_code",
              "transforms.tsconvert06.es.input.fields": "code,lang_code",
              "transforms.tsconvert06.es.output.field": "name",
              "transforms.tsconvert06.output.field": "doc_type_name"
          }
    }';
  32.prereg_reg_appointment.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="prereg_reg_appointment_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_prereg'; # change this
    DB_TABLES='prereg.reg_appointment,prereg.reg_appointment_consumed'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07,tsconvert08,tsconvert09",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "booking_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "appointment_date",
              "transforms.tsconvert04.input.type": "days_epoch",
              "transforms.tsconvert04.output.format": "yyyy-MM-dd",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "slot_from_time",
              "transforms.tsconvert05.input.type": "micro_sec",
              "transforms.tsconvert05.output.format": "HH:mm:ss",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "slot_to_time",
              "transforms.tsconvert06.input.type": "micro_sec",
              "transforms.tsconvert06.output.format": "HH:mm:ss",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "cr_dtimes",
              "transforms.tsconvert07.input.type": "micro_sec",

              "transforms.tsconvert08.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert08.field": "upd_dtimes",
              "transforms.tsconvert08.input.type": "micro_sec",

              "transforms.tsconvert09.type": "io.mosip.kafka.connect.transforms.DynamicNewField$Value",
              "transforms.tsconvert09.es.index": '\"$DB_PREFIX_INDEX.master.registration_center\"',
              "transforms.tsconvert09.es.url": '\"$ES_URL\"',
              "transforms.tsconvert09.input.fields": "regcntr_id",
              "transforms.tsconvert09.es.input.fields": "id",
              "transforms.tsconvert09.es.output.field": "name",
              "transforms.tsconvert09.output.field": "regcntr_name"
          }
    }';
  33.prereg_reg_available_slot.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="prereg_reg_available_slot_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_prereg'; # change this
    DB_TABLES='prereg.reg_available_slot'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07,tsconvert08,tsconvert09",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "availability_date",
              "transforms.tsconvert03.input.type": "days_epoch",
              "transforms.tsconvert03.output.format": "yyyy-MM-dd",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "slot_from_time",
              "transforms.tsconvert04.input.type": "micro_sec",
              "transforms.tsconvert04.output.format": "HH:mm:ss",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "slot_to_time",
              "transforms.tsconvert05.input.type": "micro_sec",
              "transforms.tsconvert05.output.format": "HH:mm:ss",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "cr_dtimes",
              "transforms.tsconvert06.input.type": "micro_sec",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "upd_dtimes",
              "transforms.tsconvert07.input.type": "micro_sec",

              "transforms.tsconvert08.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert08.field": "upd_dtimes",
              "transforms.tsconvert08.input.type": "micro_sec",

              "transforms.tsconvert09.type": "io.mosip.kafka.connect.transforms.DynamicNewField$Value",
              "transforms.tsconvert09.es.index": '\"$DB_PREFIX_INDEX.master.registration_center\"',
              "transforms.tsconvert09.es.url": '\"$ES_URL\"',
              "transforms.tsconvert09.input.fields": "regcntr_id",
              "transforms.tsconvert09.es.input.fields": "id",
              "transforms.tsconvert09.es.output.field": "name",
              "transforms.tsconvert09.output.field": "regcntr_name"
          }
    }';
  34.prereg_otp_transaction.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="prereg_otp_transaction_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_prereg'; # change this
    DB_TABLES='prereg.otp_transaction'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "generated_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "expiry_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "cr_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "upd_dtimes",
              "transforms.tsconvert06.input.type": "micro_sec",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "del_dtimes",
              "transforms.tsconvert07.input.type": "micro_sec"
          }
    }';
  40.ida_auth_transaction.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="ida_auth_transaction_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_ida'; # change this
    DB_TABLES='ida.auth_transaction'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "request_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "response_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "cr_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "upd_dtimes",
              "transforms.tsconvert06.input.type": "micro_sec",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "del_dtimes",
              "transforms.tsconvert07.input.type": "micro_sec"
          }
    }';
  50.regprc_registration.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="regprc_registration_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_regprc'; # change this
    DB_TABLES='regprc.registration'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05,tsconvert06,tsconvert07,tsconvert08",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "latest_trn_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "pkt_cr_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "cr_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec",

              "transforms.tsconvert06.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert06.field": "upd_dtimes",
              "transforms.tsconvert06.input.type": "micro_sec",

              "transforms.tsconvert07.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert07.field": "del_dtimes",
              "transforms.tsconvert07.input.type": "micro_sec",

              "transforms.tsconvert08.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert08.field": "resume_timestamp",
              "transforms.tsconvert08.input.type": "micro_sec"
          }
    }';
  51.regprc_registration_list.api: |
    # these following will be taken from env
    #DB_USER=
    #DB_PORT=
    #DB_HOSTNAME=
    #DB_PASS=
    #DB_PREFIX_INDEX=
    #ES_URL=

    CONN_NAME="regprc_registration_list_$DB_PREFIX_INDEX"; # change this.. give unique name for each db/table

    DEBEZ_CONN_URL='debezium-service.reporting:8083'; # needn't change .. this is the debezium-connector service name
    ES_CONN_URL='es-connect.reporting:8083'; # needn't change .. this is the ES-connector service name

    DB_NAME='mosip_regprc'; # change this
    DB_TABLES='regprc.registration_list'
    ES_INDICES=$(echo $DB_TABLES | sed -E "s/([^,]+)/$DB_PREFIX_INDEX.\1/g")

    curl \
      -X POST \
      http://$ES_CONN_URL/connectors \
      -H 'Content-Type: application/json' \
      -d \
      '{
          "name": '\"$CONN_NAME\"',
          "config": {
              "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
              "name": '\"$CONN_NAME\"',
              "connection.url": '\"$ES_URL\"',
              "tasks.max": "1",
              "topics": '\"$ES_INDICES\"',
              "key.ignore": "true",
              "schema.ignore": "true",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "transforms": "tsconvert01,tsconvert02,tsconvert03,tsconvert04,tsconvert05",

              "transforms.tsconvert01.type": "io.debezium.transforms.ExtractNewRecordState",
              "transforms.tsconvert01.delete.handling.mode": "rewrite",
              "transforms.tsconvert01.add.fields": "source.ts_ms:ts_ms,table,lsn",
              "transforms.tsconvert01.add.fields.prefix": "source_",

              "transforms.tsconvert02.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert02.field": "source_ts_ms",

              "transforms.tsconvert03.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert03.field": "cr_dtimes",
              "transforms.tsconvert03.input.type": "micro_sec",

              "transforms.tsconvert04.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert04.field": "upd_dtimes",
              "transforms.tsconvert04.input.type": "micro_sec",

              "transforms.tsconvert05.type": "io.mosip.kafka.connect.transforms.TimestampConverterAdv$Value",
              "transforms.tsconvert05.field": "del_dtimes",
              "transforms.tsconvert05.input.type": "micro_sec"
          }
    }';

{{ end }}
{{ end }}
